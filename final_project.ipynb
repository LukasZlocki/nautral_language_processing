{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813837c-4f74-4395-a34f-18c310b1a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projekt zaliczeniowy\n",
    "# Lukasz Zlocki\n",
    "# 76103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024d630-01f8-4195-ae90-93129c4f2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stan laborki\n",
    "# Zadanie 1\n",
    "#  - todo <- w trakcie kopiowania :)\n",
    "# Zadanie 2\n",
    "#  - punkt a : done :)\n",
    "#  - punkt b : done :)\n",
    "#  - punkt c : todo <-zrobi Lukasz\n",
    "# Zadanie 3\n",
    "#  - todo <- Adrian\n",
    "# Zadanie 4\n",
    "#  - standardowe : done :)\n",
    "#  - Zadanie z * : todo <-zrobi Lukasz\n",
    "# Zadanie 5\n",
    "#  - punkt a : todo <- zrobi Damian\n",
    "#  - punkt b : todo <- zrobi Damian\n",
    "#  - punkt c : todo <- zrobi Damian\n",
    "#  - punkt d : todo <- zrobi Damian\n",
    "# Zadanie 6\n",
    "#  - punkt a : todo\n",
    "#  - punkt b : todo\n",
    "#  - punkt c : todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708e5a7-d668-4d5b-89ce-ac32fffd00a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb93b3-025d-4d68-8e46-705316638229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZADANIE 1\n",
    "# Napisac klase, ktora umozliwia tworzenie wektorow BoW i TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a00bce-24ec-4ed0-b79f-518c0bee68a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lzloc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from math import log\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571c533f-6514-423b-bd27-3f25a00560a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVectorizer:\n",
    "    def __init__(self, use_tfidf=False, tokenizer=None, stoplist=None, stemming=False):\n",
    "        self.use_tfidf = use_tfidf\n",
    "        self.tokenizer = tokenizer if tokenizer else self.default_tokenizer\n",
    "        self.stoplist = stoplist if stoplist else set()\n",
    "        self.stemming = stemming\n",
    "        self.stemmer = PorterStemmer() if stemming else None\n",
    "        self.vocabulary = {}\n",
    "        self.idf = {}\n",
    "\n",
    "    def default_tokenizer(self, text):\n",
    "        return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        token_counts = Counter()\n",
    "        doc_freq = defaultdict(int)\n",
    "\n",
    "        for document in corpus:\n",
    "            tokens = self._process_tokens(self.tokenizer(document))\n",
    "            token_counts.update(tokens)\n",
    "            unique_tokens = set(tokens)\n",
    "            for token in unique_tokens:\n",
    "                doc_freq[token] += 1\n",
    "\n",
    "        self.vocabulary = {token: idx for idx, token in enumerate(sorted(token_counts.keys()))}\n",
    "\n",
    "        if self.use_tfidf:\n",
    "            n_docs = len(corpus)\n",
    "            self.idf = {token: log((n_docs + 1) / (freq + 1)) + 1 for token, freq in doc_freq.items()}\n",
    "\n",
    "    def transform(self, documents):\n",
    "        matrix = []\n",
    "\n",
    "        for document in documents:\n",
    "            tokens = self._process_tokens(self.tokenizer(document))\n",
    "            token_counts = Counter(tokens)\n",
    "\n",
    "            row = np.zeros(len(self.vocabulary))\n",
    "            for token, count in token_counts.items():\n",
    "                if token in self.vocabulary:\n",
    "                    if self.use_tfidf:\n",
    "                        row[self.vocabulary[token]] = count * self.idf.get(token, 0)\n",
    "                    else:\n",
    "                        row[self.vocabulary[token]] = count\n",
    "\n",
    "            matrix.append(row)\n",
    "\n",
    "        return pd.DataFrame(matrix, columns=self.vocabulary.keys())\n",
    "\n",
    "    def _process_tokens(self, tokens):\n",
    "        processed_tokens = []\n",
    "        for token in tokens:\n",
    "            if token in self.stoplist:\n",
    "                continue\n",
    "            if self.stemming:\n",
    "                token = self.stemmer.stem(token)\n",
    "            processed_tokens.append(token)\n",
    "        return processed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95af70a-ffe6-4938-88da-fd4897584978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Vectors:\n",
      "   another  bow  document  example  fun  idf  processing  sample  text   tf\n",
      "0      0.0  0.0       1.0      0.0  0.0  0.0         0.0     1.0   0.0  0.0\n",
      "1      1.0  0.0       2.0      1.0  0.0  0.0         0.0     0.0   0.0  0.0\n",
      "2      0.0  1.0       0.0      0.0  1.0  1.0         1.0     0.0   1.0  1.0\n",
      "\n",
      "TF-IDF Vectors:\n",
      "    another       bow  document   example       fun       idf  processing  \\\n",
      "0  0.000000  0.000000  1.287682  0.000000  0.000000  0.000000    0.000000   \n",
      "1  1.693147  0.000000  2.575364  1.693147  0.000000  0.000000    0.000000   \n",
      "2  0.000000  1.693147  0.000000  0.000000  1.693147  1.693147    1.693147   \n",
      "\n",
      "     sample      text        tf  \n",
      "0  1.693147  0.000000  0.000000  \n",
      "1  0.000000  0.000000  0.000000  \n",
      "2  0.000000  1.693147  1.693147  \n"
     ]
    }
   ],
   "source": [
    "# Test klasy\n",
    "corpus = [\n",
    "        \"This is a sample document.\",\n",
    "        \"This document is another example document.\",\n",
    "        \"Text processing with BoW and TF-IDF is fun!\"\n",
    "    ]\n",
    "stoplist = set(stopwords.words(\"english\"))\n",
    "\n",
    "# BoW\n",
    "bow_vectorizer = CustomVectorizer(stoplist=stoplist)\n",
    "bow_vectorizer.fit(corpus)\n",
    "bow_vectors = bow_vectorizer.transform(corpus)\n",
    "print(\"BoW Vectors:\")\n",
    "print(bow_vectors)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = CustomVectorizer(use_tfidf=True, stoplist=stoplist)\n",
    "tfidf_vectorizer.fit(corpus)\n",
    "tfidf_vectors = tfidf_vectorizer.transform(corpus)\n",
    "print(\"\\nTF-IDF Vectors:\")\n",
    "print(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5dc87-3b0d-4d3a-b42f-e5d405f4ae28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d5a55-19d4-46bc-ae36-0c33eb192436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZADANIE 2.a\n",
    "# Wyszukiwarka dokumentow ze zbioru 20newsgroups\n",
    "# Podobienstwo cosinusowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379afc14-f574-4ceb-9235-76c8d68726fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad79ebef-7340-478a-a611-b2673aee50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych 20newsgroups\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "documents = newsgroups.data\n",
    "\n",
    "documents\n",
    "\n",
    "# Stwórz wektor TF-IDF dla dokumentów\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35fe603b-bbb1-4259-8212-697db623f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podobienstwo cosinusowe\n",
    "def get_similar_docs_by_cosine(query_string, top_docs_quantity):\n",
    "    '''\n",
    "    Retrive documents with cosine similarity\n",
    "    \n",
    "    parameters:\n",
    "        query_string - string with query\n",
    "        top_docs_quantity - quantity of top similar documents to print\n",
    "    \n",
    "    returns:\n",
    "    list: A list of tuples, each containing a document and its cosine similarity score.\n",
    "    '''\n",
    "    # Przekształcenie zapytania w wektor TF-IDF \n",
    "    query_tfidf = vectorizer.transform([query_string]) \n",
    "    # Obliczenie podobieństwa cosinusowego pomiędzy zapytaniem a dokumentami \n",
    "    cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten() \n",
    "    # Znajdź indeksy dokumentów o największym podobieństwie kosinusowym \n",
    "    top_indices = cosine_similarities.argsort()[-top_docs_quantity:][::-1] \n",
    "    # Zwróć posortowaną listę dokumentów \n",
    "    return [(documents[i], cosine_similarities[i]) for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc64e7c-6e43-48b8-a6a4-7c55ea0944fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar news to query: reading Bible\n",
      "------------------------------\n",
      "Similarity: 0.4067\n",
      "From: spebcg@thor.cf.ac.uk (BCG)\n",
      "Subject: Re: Knowing God's Will\n",
      "Organization: uwcc\n",
      "Lines: 20\n",
      "\n",
      "Hi,\n",
      "\n",
      "I don't know much about Bible. Could you tell me the relations of\n",
      "Christians with non-Christians in Bible? How should be The relations of\n",
      "christian nations with each other and the relations of Christian nations\n",
      "with other nations who are not Christians?\n",
      "\n",
      "The other question is about the concept of religion in Bible. Does the\n",
      "religion of God include and necessitate any law to be extracted from\n",
      "Bible\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.3988\n",
      "From: halsall@murray.fordham.edu (Paul Halsall)\n",
      "Subject: Bible Unsuitable for New Christians\n",
      "Reply-To: halsall@murray.fordham.edu\n",
      "Organization: J. Random Misconfigured Site\n",
      "Lines: 42\n",
      "\n",
      "\n",
      "\tA \"new Christian\" wrote that he was new to the faith and \n",
      "learning about it \"by reading the Bible, of course\". I am not\n",
      "at all sure this is the best path to follow.\n",
      "\tWhile the Bible is, for Christians, the word of God, the \n",
      "revelation of God is Jesus Christ and the chief legacy of this\n",
      "revalation is the Church. I\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.3499\n",
      "From: 18669@bach.udel.edu (Steven R Hoskins)\n",
      "Subject: Some questions from a new Christian\n",
      "Organization: University of Delaware\n",
      "Lines: 40\n",
      "\n",
      "Hi,\n",
      "\n",
      "I am new to this newsgroup, and also fairly new to christianity. I was\n",
      "raised as a Unitarian and have spent the better part of my life as an\n",
      "agnostic, but recently I have developed the firm conviction that the\n",
      "Christian message is correct and I have accepted Jesus into my life. I am\n",
      "happy, but I realize I am very ignorant about much of the Bible and\n",
      "quite\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.3172\n",
      "Subject: Re: [rw] Is Robert Weiss the only orthodox Christian?\n",
      "From: <LIBRBA@BYUVM.BITNET>\n",
      "Organization: Brigham Young University\n",
      "Lines: 66\n",
      "\n",
      "In article <C5vGyD.H7s@acsu.buffalo.edu>, psyrobtw@ubvmsd.cc.buffalo.edu (Robert\n",
      "Weiss) says:\n",
      ">\n",
      ">     \"Orthodox\" is a compound word. It comes from 'orthos' (straight, true,\n",
      ">     right) and from 'doxa' (opinion, doctrine, teaching). I use orthodox to\n",
      ">     refer to 'right teaching.' Right teaching is derived from letting God\n",
      ">     speak to us through the Bi\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.3169\n",
      "From: creps@lateran.ucs.indiana.edu (Stephen A. Creps)\n",
      "Subject: Re: Does it matter which church?\n",
      "Organization: Indiana University\n",
      "Lines: 22\n",
      "\n",
      "In article <May.2.09.51.04.1993.11807@geneva.rutgers.edu> gideon@otago.ac.nz (Gideon King) writes:\n",
      ">When the Protestant reformers opposed and subsequently separated from the  \n",
      ">Church of Rome, the battle cry of the new protesting religion was \"The  \n",
      ">Bible, the whole Bible, and nothing but the Bible\". Underlying that cry  \n",
      ">was a theory that if people could\n",
      "---\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Przykładowe zapytanie 1 - podobienstwo cosiunusowe\n",
    "query = \"reading Bible\" \n",
    "top_documents = get_similar_docs_by_cosine(query, 5) \n",
    "# Wypisz wyniki \n",
    "print(f\"Top 5 most similar news to query: \" + query)\n",
    "for doc, score in top_documents: \n",
    "    print(f\"------------------------------\")\n",
    "    print(f\"Similarity: {score:.4f}\")\n",
    "    print(f\"{doc[:500]}\\n---\\n\")\n",
    "    print(f\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5445f7e5-dfb2-4776-8c1f-05f4c87863ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar news to query: toyota and honda are the best cars\n",
      "------------------------------\n",
      "Similarity: 0.3241\n",
      "From: carl_f_hoffman@cup.portal.com\n",
      "Subject: 1993 Infiniti G20\n",
      "Organization: The Portal System (TM)\n",
      "Lines: 26\n",
      "\n",
      "\n",
      "I am thinking about getting an Infiniti G20.\n",
      "In consumer reports it is ranked high in many\n",
      "catagories including highest in reliability index for compact cars.\n",
      "Mitsubushi Galant was second followed by Honda Accord).\n",
      "\n",
      "A couple of things though:\n",
      "1) In looking around I have yet to see anyone driving this\n",
      "   car. I see lots of Honda's and Toyota's.\n",
      "2) There is a special deal where I can get\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.2480\n",
      "From: gt4722a@prism.gatech.EDU (James B. Atkins)\n",
      "Subject: Honda Mailing list?\n",
      "Organization: Georgia Institute of Technology\n",
      "Lines: 2\n",
      "\n",
      "\n",
      "\tIs there a Honda mailing list, and if so how do I subscribe to it?\n",
      "\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.2246\n",
      "From: srihari@cirrus.com (Srihari Shoroff)\n",
      "Subject: Re: Instead of a Saturn SC2, What???\n",
      "Organization: Cirrus Logic Inc.\n",
      "Distribution: na\n",
      "Lines: 24\n",
      "\n",
      "In <Ifn=sPO00iV18_A8NZ@andrew.cmu.edu> jr4q+@andrew.cmu.edu (Jason M. Roth) writes:\n",
      "\n",
      ">>R&T had an article on cars of the SC1 ilk and they liked the Civic Ex,\n",
      ">>the Escort GT and the MX-3 best of all, and the SC1 was way down the\n",
      ">>list except for braking.\n",
      "\n",
      ">I just looked at that article; first of all, this summary is inaccurate;\n",
      ">of 10 cars, the SC1\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.2143\n",
      "From: bep1@cbnewsg.cb.att.com (bentz.e.puryear)\n",
      "Subject: Re: Sport Utility Vehical comparisons? Any Opinions?\n",
      "Organization: AT&T\n",
      "Lines: 51\n",
      "\n",
      "From article <1r1i7mINN4n4@cronkite.cisco.com>, by kmac@cisco.com (Karl Elvis MacRae):\n",
      "> \n",
      "> \n",
      "> \tI just read articals on this in Road and Track and Car and Driver\n",
      "> \t(Is that one mag or two? =B^), and I was wondering if people out\n",
      "> \tthere have any opinions that differed from what these mags have to\n",
      "> \tsay...\n",
      "> \n",
      "> \n",
      "> \tI'm looking at the following three SUV's;\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.2057\n",
      "From: \"Arun G. Jayakumar\" <aj22+@andrew.cmu.edu>\n",
      "Subject: Re: Honda Mailing list?\n",
      "Organization: Freshman, Biology, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 6\n",
      "NNTP-Posting-Host: andrew.cmu.edu\n",
      "In-Reply-To: <94539@hydra.gatech.EDU>\n",
      "\n",
      "Excerpts from netnews.rec.autos: 24-Apr-93 Honda Mailing list? by James\n",
      "B. Atkins@prism.ga \n",
      ">         Is there a Honda mailing list, and if so how do I subscribe to it?\n",
      "\n",
      "If you look at their magazine ads, they may have a phone number to call\n",
      "and you can ask for a catalog\n",
      "---\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Przykladowe zapytanie 2 - podobienstwo cosiunusowe\n",
    "query = \"toyota and honda are the best cars\" \n",
    "top_documents = get_similar_docs_by_cosine(query, 5) \n",
    "# Wypisz wyniki \n",
    "print(f\"Top 5 most similar news to query: \" + query)\n",
    "for doc, score in top_documents: \n",
    "    print(f\"------------------------------\")\n",
    "    print(f\"Similarity: {score:.4f}\")\n",
    "    print(f\"{doc[:500]}\\n---\\n\")\n",
    "    print(f\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c82c3-85d9-4c0f-b5b2-101489669d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZADANIE 2a - wnioski:\n",
    "\n",
    "# Dzieki funkcji get_similar_docs_by_cosine obliczylem miare podobienstw miedzy zapytaniem (query) oraz kazdym dokumentem w korpusie.\n",
    "# Wyniki zostaly posortowane od wartosci najwiekszej do najmniejszej po wartosci podobienstwa(similarity).\n",
    "# Wyswietlone wyniki powyzej pokazuja maile o najwiekszym podobienstwie do zadanego zapytania.\n",
    "# W przypadku zapytan \"reading Bible\" czy \"toyota and honda are the best cars\"  wskazane zostaly prawidlowo emaile dotyczace danego zagadnienia\n",
    "# Stopien podobienstwa wyswietlonych emaili 0.2 - 0.22 oraz 0.39 - 0.42. \n",
    "# Przy tym stopniu podobienstwa 0.39 - 0.42.  prawidlowo oceniam dobor emaili do zadanego zapytania (query) \n",
    "# Zauwazylem , ze przy stopniu podobienstwa 0.2 - 0.22 ten dobor maili tez oceniam jako prawidlowy i zgodny z tematem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe4557-f9ec-4ba7-afbd-02491a3645a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53827a-fac9-4272-acb6-72fb2701f438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d617f3-38d7-4cbd-a008-667f04cdfc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZADANIE 2.b\n",
    "# Wyszukiwarka dokumentow ze zbioru 20newsgroups\n",
    "# iloczyn skalarny zamiast podobienstwa kosinusowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04489cff-ce3f-4600-ad86-ef71325eb6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_docs_by_scalar(query, vectorizer, tfidf_matrix, top_n): \n",
    "    '''\n",
    "    Retrive similar documents by scalar similarity\n",
    "    parameters:\n",
    "        query (str): String containing the query to search for similar documents. \n",
    "        vectorizer: TF-IDF vectorizer used to transform the query and documents into vector form. \n",
    "        tfidf_matrix: TF-IDF matrix representing the collection of documents. \n",
    "        top_n (int): Number of top similar documents to retrieve.\n",
    "    Returns: \n",
    "        top_indices (array): Indices of the top n most similar documents. \n",
    "        scalar_products (array): Scalar similarity scores of the top n documents. \n",
    "    '''  \n",
    "    # Konwersja zapytania do wektora TF-IDF \n",
    "    query_vector = vectorizer.transform([query]) \n",
    "    # Obliczenie iloczynu skalarnego między zapytaniem a wszystkimi dokumentami \n",
    "    scalar_products = np.dot(query_vector, tfidf_matrix.T).toarray().flatten() \n",
    "    # Znalezienie indeksów dokumentów o najwyższym iloczynie skalarnym \n",
    "    top_indices = scalar_products.argsort()[-top_n:][::-1] \n",
    "    return top_indices, scalar_products[top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79890278-fdf4-41fa-8e37-7d4a8ac51df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.3241\n",
      "From: carl_f_hoffman@cup.portal.com\n",
      "Subject: 1993 Infiniti G20\n",
      "Organization: The Portal System (TM)\n",
      "Lines: 26\n",
      "\n",
      "\n",
      "I am thinking about getting an Infiniti G20.\n",
      "In consumer reports it is ranked high in many\n",
      "catagories including highest in reliability index for compact cars.\n",
      "Mitsubushi Galant was second followed by Honda Accord).\n",
      "\n",
      "A couple of things though:\n",
      "1) In looking around I have yet to see anyone driving this\n",
      "   car. I see lots of Honda's and Toyota's.\n",
      "2) There is a special deal where I can get\n",
      "---\n",
      "\n",
      "Similarity: 0.2480\n",
      "From: gt4722a@prism.gatech.EDU (James B. Atkins)\n",
      "Subject: Honda Mailing list?\n",
      "Organization: Georgia Institute of Technology\n",
      "Lines: 2\n",
      "\n",
      "\n",
      "\tIs there a Honda mailing list, and if so how do I subscribe to it?\n",
      "\n",
      "---\n",
      "\n",
      "Similarity: 0.2246\n",
      "From: srihari@cirrus.com (Srihari Shoroff)\n",
      "Subject: Re: Instead of a Saturn SC2, What???\n",
      "Organization: Cirrus Logic Inc.\n",
      "Distribution: na\n",
      "Lines: 24\n",
      "\n",
      "In <Ifn=sPO00iV18_A8NZ@andrew.cmu.edu> jr4q+@andrew.cmu.edu (Jason M. Roth) writes:\n",
      "\n",
      ">>R&T had an article on cars of the SC1 ilk and they liked the Civic Ex,\n",
      ">>the Escort GT and the MX-3 best of all, and the SC1 was way down the\n",
      ">>list except for braking.\n",
      "\n",
      ">I just looked at that article; first of all, this summary is inaccurate;\n",
      ">of 10 cars, the SC1\n",
      "---\n",
      "\n",
      "Similarity: 0.2143\n",
      "From: bep1@cbnewsg.cb.att.com (bentz.e.puryear)\n",
      "Subject: Re: Sport Utility Vehical comparisons? Any Opinions?\n",
      "Organization: AT&T\n",
      "Lines: 51\n",
      "\n",
      "From article <1r1i7mINN4n4@cronkite.cisco.com>, by kmac@cisco.com (Karl Elvis MacRae):\n",
      "> \n",
      "> \n",
      "> \tI just read articals on this in Road and Track and Car and Driver\n",
      "> \t(Is that one mag or two? =B^), and I was wondering if people out\n",
      "> \tthere have any opinions that differed from what these mags have to\n",
      "> \tsay...\n",
      "> \n",
      "> \n",
      "> \tI'm looking at the following three SUV's;\n",
      "---\n",
      "\n",
      "Similarity: 0.2057\n",
      "From: \"Arun G. Jayakumar\" <aj22+@andrew.cmu.edu>\n",
      "Subject: Re: Honda Mailing list?\n",
      "Organization: Freshman, Biology, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 6\n",
      "NNTP-Posting-Host: andrew.cmu.edu\n",
      "In-Reply-To: <94539@hydra.gatech.EDU>\n",
      "\n",
      "Excerpts from netnews.rec.autos: 24-Apr-93 Honda Mailing list? by James\n",
      "B. Atkins@prism.ga \n",
      ">         Is there a Honda mailing list, and if so how do I subscribe to it?\n",
      "\n",
      "If you look at their magazine ads, they may have a phone number to call\n",
      "and you can ask for a catalog\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie danych 20newsgroups\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "documents = newsgroups.data\n",
    "\n",
    "# Stwórz wektor TF-IDF dla dokumentów\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Przykladowe zapytanie:\n",
    "query = \"toyota and honda are the best cars\"\n",
    "\n",
    "#Iloczyn skalarny podobienstw\n",
    "top_indices_skalar, top_scores_skalar = get_similar_docs_by_scalar(query, vectorizer, tfidf_matrix, 5)\n",
    "\n",
    "# Wyświetlenie wyników \n",
    "for doc_skalar, score_skalar in zip(top_indices_skalar, top_scores_skalar): \n",
    "    print(f\"Similarity: {score_skalar:.4f}\\n{documents[doc_skalar][:500]}\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848cd3f-b340-4c9a-8e77-ae30a4f1934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZADANIE 2b - wnioski:\n",
    "# W punkcie b zastosowalem iloczyn skalarny podobienstwa , wynik w porownaniu do podobiensta cosinusowego i dla tego samego\n",
    "# zapytania \"toyota and honda are the best cars\" jest identyczny. obliczony wskaznik podobienstwa tez jest na tym samym poziomie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168d7f2-b810-490b-873e-e9274cacd99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5bb94-81d2-41ca-ac2f-57baa9516aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dda5af8-04f0-4bdc-b0ab-3813e88ab526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZADANIE 4\n",
    "# Dla każdej grupy ze zbioru  20newsgroups wypisz inną grupę najbardziej i najmniej podobną znaczeniowo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc87dd4e-1178-457e-abad-35856be2f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the average cosine similarity between two groups\n",
    "def get_average_cosine_similarity(group1_indices, group2_indices): \n",
    "    \"\"\"\n",
    "    Calculate the average cosine similarity between two groups of documents.\n",
    "\n",
    "    Parameters: \n",
    "        group1_indices : array-like Indices of the documents in the first group. \n",
    "        group2_indices : array-like Indices of the documents in the second group. \n",
    "        \n",
    "    Returns: \n",
    "        float: The average cosine similarity between the two groups of documents.   \n",
    "    \"\"\"\n",
    "    # Use cosine_similarity from sklearn\n",
    "    similarities = cosine_similarity(tfidf_matrix[group1_indices], tfidf_matrix[group2_indices]) \n",
    "    return np.mean(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1744056c-fc64-4ebc-87fc-8d1f12816307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load needed libraries\n",
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c726caf-3399-4779-b61d-8bd65277d20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from 20newsgroups\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Divide documents between categories and labels\n",
    "documents = newsgroups.data\n",
    "categories = newsgroups.target_names \n",
    "labels = newsgroups.target\n",
    "\n",
    "# Transform text to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "#Print categories\n",
    "print(\"Categories:\") \n",
    "categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8a9be89-7604-4706-99bc-8b390eb84e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST similar groups:\n",
      "('soc.religion.christian', 'talk.religion.misc')\n",
      "similarity:\n",
      "0.02346466873647374\n",
      "\n",
      "LEAST similar groups:\n",
      "('comp.windows.x', 'rec.sport.hockey')\n",
      "similarity:\n",
      "0.0071516829474918995\n"
     ]
    }
   ],
   "source": [
    "# Calculating average cosine similarity for all pairs of groups\n",
    "group_similarities = {} \n",
    "for i in range(len(categories)): \n",
    "    for j in range(i+1, len(categories)): \n",
    "        group1_indices = np.where(labels == i)[0] \n",
    "        group2_indices = np.where(labels == j)[0] \n",
    "        similarity = get_average_cosine_similarity(group1_indices, group2_indices) \n",
    "        group_similarities[(categories[i], categories[j])] = similarity\n",
    "\n",
    "# Indicate most and least similar groups\n",
    "most_similar_groups = max(group_similarities, key=group_similarities.get) \n",
    "least_similar_groups = min(group_similarities, key=group_similarities.get)\n",
    "\n",
    "# Printing results\n",
    "print(\"MOST similar groups:\")\n",
    "print(f\"{most_similar_groups}\")\n",
    "print(f\"similarity:\") \n",
    "print(f\"{group_similarities[most_similar_groups]}\")\n",
    "print(\"\")\n",
    "print(\"LEAST similar groups:\")\n",
    "print(f\"{least_similar_groups}\")\n",
    "print(\"similarity:\")\n",
    "print(f\"{group_similarities[least_similar_groups]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1dcfcc-e499-416e-8026-a00c5056a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZADANIE 4 - wnioski:\n",
    "# Przy uzyciu metody kosinusowego prawdopodobienstwa wyznaczono grupy najbardziej oraz najmniej podobne\n",
    "# Grupy najbardziej podobne (similarity: 0.02346) to grupy 'soc.religion.christian', 'talk.religion.misc' i tu widac , ze grupy zwiazane sa z religia\n",
    "# Grupy najmniej podobne (similarity: 0.0071) to grupy 'comp.windows.x', 'rec.sport.hockey' hokej oraz computery/windows to sa rozne tematy.\n",
    "# Zadanie zakonczone sukcesem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c131ddcc-1ea9-4d43-a2fb-71c83642a397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69725de9-ae40-4d57-b30c-1a31d677007b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d1256e-8cd1-44b8-8b58-1d85bcbbabfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
