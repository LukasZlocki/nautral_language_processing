{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63d02bb6-f2a5-438c-b13d-8adf30caccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadanie 3 - projekt\n",
    "# Lukasz Zlocki\n",
    "# 76103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "120d78cf-6ac6-4561-a031-d3856f519c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "#treebank tokenizer:\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# countvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "93cf6b9e-5527-407a-883d-3ce5a5bcd86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizers\n",
    "def tokenizer_treebank(text):\n",
    "    tokenizer_treebank = TreebankWordTokenizer().tokenize(text)\n",
    "    return tokenizer_treebank\n",
    "\n",
    "def word_tokenizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ee4620cf-f974-454d-8619-0265a4566c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['better', 'done', 'is', 'said', 'than', 'well'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test BoW\n",
    "txt1 = 'Well done is better than well said'\n",
    "\n",
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform([txt1])\n",
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b86f52a6-4786-44ae-923c-b0e7cb0b066b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "88c904aa-720f-4291-81ab-5c671a1b9b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>better</th>\n",
       "      <th>done</th>\n",
       "      <th>is</th>\n",
       "      <th>said</th>\n",
       "      <th>than</th>\n",
       "      <th>well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   better  done  is  said  than  well\n",
       "0       1     1   1     1     1     2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(bow.toarray(), columns = cv.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08cc95a4-736e-4a58-8751-d0b899c73837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAN DZIALANIA\n",
    "# vektor CountVectorized CUSTOM MADE\n",
    "# jak stworzyc:\n",
    "# stworzyc 3x krotki text w zmiennych txt1, txt2, ...\n",
    "# dobrowadzic zmienne do malych liter, wyeliminowac znaki inne niz litera, cyfra\n",
    "# stworzyc BOW dla tych trzech zmiennych : jest to opisane w wykladzie 3 postapic identycznie\n",
    "# teraz nalezy stworzyc wlasny countVectorized\n",
    "    # pobrac wszystkie wyrazy z BOW do tablicy\n",
    "    # ulozyc wyrazy w kolejnosci alfabetycznej\n",
    "    # dla kazdej zmiennej utworzyc nowa zmienna lustrzana ale wstawiamy tam wszystie wyrazy i liczym\n",
    "    # ile razy wystapily w danej zmiennej (zapewne jakis foreach)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "75a4be0a-168a-4aaf-a5e0-2b8d2086865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START : CountVectorized CUSTOM MADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b5ae6602-5416-4c97-aa91-d05c2996e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done is better than well said\n",
      "Ask not what the Earth can do for you; ask what you can do for the Earth.\n",
      "Government of the people, by the people, and for the people shall not perish from the earth\n"
     ]
    }
   ],
   "source": [
    "# Creation of base strings\n",
    "txt1 = 'Well done is better than well said'\n",
    "txt2 = 'Ask not what the Earth can do for you; ask what you can do for the Earth.'\n",
    "txt3 = 'Government of the people, by the people, and for the people shall not perish from the earth'\n",
    "\n",
    "print(txt1)\n",
    "print(txt2)\n",
    "print(txt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dd9269e1-775b-4b96-932f-8f275fd72ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well done is better than well said\n",
      "ask not what the earth can do for you; ask what you can do for the earth.\n",
      "government of the people, by the people, and for the people shall not perish from the earth\n"
     ]
    }
   ],
   "source": [
    "# prepare base string to lower signs\n",
    "txt1_lower = txt1.lower()\n",
    "txt2_lower = txt2.lower()\n",
    "txt3_lower = txt3.lower()\n",
    "\n",
    "print(txt1_lower)\n",
    "print(txt2_lower)\n",
    "print(txt3_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b25baffe-3f48-4377-822e-47b00819ae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'done', 'is', 'better', 'than', 'well', 'said']\n",
      "['ask', 'not', 'what', 'the', 'earth', 'can', 'do', 'for', 'you', ';', 'ask', 'what', 'you', 'can', 'do', 'for', 'the', 'earth', '.']\n",
      "['government', 'of', 'the', 'people', ',', 'by', 'the', 'people', ',', 'and', 'for', 'the', 'people', 'shall', 'not', 'perish', 'from', 'the', 'earth']\n"
     ]
    }
   ],
   "source": [
    "#-------------\n",
    "# BOW creation\n",
    "#-------------\n",
    "\n",
    "#---------------\n",
    "# words tokenize\n",
    "#---------------\n",
    "\n",
    "# tokenize txt1, txt2, ...\n",
    "txt1_tokenized = tokenize_treebank(txt1_lower)\n",
    "txt2_tokenized = tokenize_treebank(txt2_lower)\n",
    "txt3_tokenized = tokenize_treebank(txt3_lower)\n",
    "\n",
    "# tokenize txt1, txt2, words only without speciali signs\n",
    "#txt1_tokenized = word_tokenizer(txt1_lower)\n",
    "#txt2_tokenized = word_tokenizer(txt2_lower)\n",
    "#txt3_tokenized = word_tokenizer(txt3_lower)\n",
    "\n",
    "print(txt1_tokenized)\n",
    "print(txt2_tokenized)\n",
    "print(txt3_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ae88e9fc-ec95-4874-9024-d483ac7fa8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---}\n",
      "Counter({'well': 2, 'done': 1, 'is': 1, 'better': 1, 'than': 1, 'said': 1})\n",
      "---}\n",
      "Counter({'ask': 2, 'what': 2, 'the': 2, 'earth': 2, 'can': 2, 'do': 2, 'for': 2, 'you': 2, 'not': 1, ';': 1, '.': 1})\n",
      "---}\n",
      "Counter({'the': 4, 'people': 3, ',': 2, 'government': 1, 'of': 1, 'by': 1, 'and': 1, 'for': 1, 'shall': 1, 'not': 1, 'perish': 1, 'from': 1, 'earth': 1})\n",
      "---}\n"
     ]
    }
   ],
   "source": [
    "#-------------\n",
    "# BOW creation\n",
    "#-------------\n",
    "\n",
    "#---------------\n",
    "# words counting\n",
    "#---------------\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "bow1 = Counter(txt1_tokenized)\n",
    "bow2 = Counter(txt2_tokenized)\n",
    "bow3 = Counter(txt3_tokenized)\n",
    "\n",
    "print(\"---}\")\n",
    "print(f\"{bow1}\")\n",
    "print(\"---}\")\n",
    "print(f\"{bow2}\")\n",
    "print(\"---}\")\n",
    "print(f\"{bow3}\")\n",
    "print(\"---}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ce4fa9e6-6d5b-4a20-b634-f3a0f29b17e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "['well', 'done', 'is', 'better', 'than', 'said']\n",
      "-----\n",
      "['well', 'done', 'is', 'better', 'than', 'said', 'ask', 'not', 'what', 'the', 'earth', 'can', 'do', 'for', 'you', ';', '.']\n",
      "-----\n",
      "['well', 'done', 'is', 'better', 'than', 'said', 'ask', 'not', 'what', 'the', 'earth', 'can', 'do', 'for', 'you', ';', '.', 'government', 'of', 'people', ',', 'by', 'and', 'shall', 'perish', 'from']\n",
      "-----\n",
      "['well', 'done', 'is', 'better', 'than', 'said', 'ask', 'not', 'what', 'the', 'earth', 'can', 'do', 'for', 'you', ';', '.', 'government', 'of', 'people', ',', 'by', 'and', 'shall', 'perish', 'from']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Create custom FIT method\n",
    "# -------------------------\n",
    "\n",
    "# stworzyc liste z tokenami all_tokens\n",
    "# stworzyc funkcje ktora jako parametrt przyjmie liste z wszystkimi tokenami oraz opszcegolna liste tokonow\n",
    "#    - sprawdzenie czy na liscie jest dany token jesli nie dorzucenie go do listy all_tokens\n",
    "\n",
    "all_tokens = []\n",
    "\n",
    "# fit all tokens at once\n",
    "def custom_fit(tokens):\n",
    "    fit_tokens = []\n",
    "    for tkns in tokens:\n",
    "        for token in tkns:\n",
    "            if token in fit_tokens:\n",
    "                continue\n",
    "            else:\n",
    "                fit_tokens.append(element)\n",
    "\n",
    "# fit tokens one by one token list\n",
    "def custom_fit_all_tokens(all_tokens, tokens_to_add):\n",
    "    updated_all_tokens = all_tokens\n",
    "    for element in tokens_to_add:\n",
    "        if element in all_tokens:\n",
    "            continue\n",
    "        else:\n",
    "            updated_all_tokens.append(element)\n",
    "    return updated_all_tokens\n",
    "\n",
    "# Check #1:\n",
    "all_tokens = custom_fit_all_tokens(all_tokens, bow1)\n",
    "print(\"-----\")\n",
    "print(f\"{all_tokens}\")\n",
    "\n",
    "# Check #2:\n",
    "all_tokens = custom_fit_all_tokens(all_tokens, bow2)\n",
    "print(\"-----\")\n",
    "print(f\"{all_tokens}\")\n",
    "\n",
    "# Check #3:\n",
    "all_tokens = custom_fit_all_tokens(all_tokens, bow3)\n",
    "print(\"-----\")\n",
    "print(f\"{all_tokens}\")\n",
    "\n",
    "# Check #4: - test: samew bow1 added . expected: not adding additional tokens which are already in list \n",
    "all_tokens = get_all_tokens(all_tokens, bow3)\n",
    "print(\"-----\")\n",
    "print(f\"{all_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c4203-3d13-4e1d-beb7-8f88da32a72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "437aafb0-72a2-4bbe-bd18-88397912e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZADANIE 2\n",
    "# Wyszukiwarka dokumentow ze zbioru 20newgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc75e8bc-4f6e-437f-b4a3-7609e2c4187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e9f15aa-1a0a-4177-99ea-39bb3b768167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych 20newsgroups\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "documents = newsgroups.data\n",
    "\n",
    "documents\n",
    "\n",
    "# Stwórz wektor TF-IDF dla dokumentów\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "53a7ad9d-e165-47f1-90ff-aad0bb710856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_docs_by_cosine(query_string, top_docs_quantity):\n",
    "    # Przekształcenie zapytania w wektor TF-IDF \n",
    "    query_tfidf = vectorizer.transform([query_string]) \n",
    "    # Obliczenie podobieństwa cosinusowego pomiędzy zapytaniem a dokumentami \n",
    "    cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten() \n",
    "    # Znajdź indeksy dokumentów o największym podobieństwie kosinusowym \n",
    "    top_indices = cosine_similarities.argsort()[-top_docs_quantity:][::-1] \n",
    "    # Zwróć posortowaną listę dokumentów \n",
    "    return [(documents[i], cosine_similarities[i]) for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8a085f36-4035-4fe5-816c-f7c53175191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Similarity: 0.4067\n",
      "From: spebcg@thor.cf.ac.uk (BCG)\n",
      "Subject: Re: Knowing God's Will\n",
      "Organization: uwcc\n",
      "Lines: 20\n",
      "\n",
      "Hi,\n",
      "\n",
      "I don't know much about Bible. Could you tell me the relations of\n",
      "Christians with non-Christians in Bible? How should be The relations of\n",
      "christian nations with each other and the relations of Christian nations\n",
      "with other nations who are not Christians?\n",
      "\n",
      "The other question is about the concept of religion in Bible. Does the\n",
      "religion of God include and necessitate any law to be extracted from\n",
      "Bible\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.3988\n",
      "From: halsall@murray.fordham.edu (Paul Halsall)\n",
      "Subject: Bible Unsuitable for New Christians\n",
      "Reply-To: halsall@murray.fordham.edu\n",
      "Organization: J. Random Misconfigured Site\n",
      "Lines: 42\n",
      "\n",
      "\n",
      "\tA \"new Christian\" wrote that he was new to the faith and \n",
      "learning about it \"by reading the Bible, of course\". I am not\n",
      "at all sure this is the best path to follow.\n",
      "\tWhile the Bible is, for Christians, the word of God, the \n",
      "revelation of God is Jesus Christ and the chief legacy of this\n",
      "revalation is the Church. I\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.3499\n",
      "From: 18669@bach.udel.edu (Steven R Hoskins)\n",
      "Subject: Some questions from a new Christian\n",
      "Organization: University of Delaware\n",
      "Lines: 40\n",
      "\n",
      "Hi,\n",
      "\n",
      "I am new to this newsgroup, and also fairly new to christianity. I was\n",
      "raised as a Unitarian and have spent the better part of my life as an\n",
      "agnostic, but recently I have developed the firm conviction that the\n",
      "Christian message is correct and I have accepted Jesus into my life. I am\n",
      "happy, but I realize I am very ignorant about much of the Bible and\n",
      "quite\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.3172\n",
      "Subject: Re: [rw] Is Robert Weiss the only orthodox Christian?\n",
      "From: <LIBRBA@BYUVM.BITNET>\n",
      "Organization: Brigham Young University\n",
      "Lines: 66\n",
      "\n",
      "In article <C5vGyD.H7s@acsu.buffalo.edu>, psyrobtw@ubvmsd.cc.buffalo.edu (Robert\n",
      "Weiss) says:\n",
      ">\n",
      ">     \"Orthodox\" is a compound word. It comes from 'orthos' (straight, true,\n",
      ">     right) and from 'doxa' (opinion, doctrine, teaching). I use orthodox to\n",
      ">     refer to 'right teaching.' Right teaching is derived from letting God\n",
      ">     speak to us through the Bi\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.3169\n",
      "From: creps@lateran.ucs.indiana.edu (Stephen A. Creps)\n",
      "Subject: Re: Does it matter which church?\n",
      "Organization: Indiana University\n",
      "Lines: 22\n",
      "\n",
      "In article <May.2.09.51.04.1993.11807@geneva.rutgers.edu> gideon@otago.ac.nz (Gideon King) writes:\n",
      ">When the Protestant reformers opposed and subsequently separated from the  \n",
      ">Church of Rome, the battle cry of the new protesting religion was \"The  \n",
      ">Bible, the whole Bible, and nothing but the Bible\". Underlying that cry  \n",
      ">was a theory that if people could\n",
      "---\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Przykładowe zapytanie \n",
    "query = \"reading Bible\" \n",
    "top_documents = get_similar_docs_by_cosine(query, 5) \n",
    "# Wypisz wyniki \n",
    "for doc, score in top_documents: \n",
    "    print(f\"------------------------------\")\n",
    "    print(f\"Similarity: {score:.4f}\")\n",
    "    print(f\"{doc[:500]}\\n---\\n\")\n",
    "    print(f\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "60da5b7c-65ea-4514-81b1-ac0c536b41e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Similarity: 0.3241\n",
      "From: carl_f_hoffman@cup.portal.com\n",
      "Subject: 1993 Infiniti G20\n",
      "Organization: The Portal System (TM)\n",
      "Lines: 26\n",
      "\n",
      "\n",
      "I am thinking about getting an Infiniti G20.\n",
      "In consumer reports it is ranked high in many\n",
      "catagories including highest in reliability index for compact cars.\n",
      "Mitsubushi Galant was second followed by Honda Accord).\n",
      "\n",
      "A couple of things though:\n",
      "1) In looking around I have yet to see anyone driving this\n",
      "   car. I see lots of Honda's and Toyota's.\n",
      "2) There is a special deal where I can get\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.2480\n",
      "From: gt4722a@prism.gatech.EDU (James B. Atkins)\n",
      "Subject: Honda Mailing list?\n",
      "Organization: Georgia Institute of Technology\n",
      "Lines: 2\n",
      "\n",
      "\n",
      "\tIs there a Honda mailing list, and if so how do I subscribe to it?\n",
      "\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.2246\n",
      "From: srihari@cirrus.com (Srihari Shoroff)\n",
      "Subject: Re: Instead of a Saturn SC2, What???\n",
      "Organization: Cirrus Logic Inc.\n",
      "Distribution: na\n",
      "Lines: 24\n",
      "\n",
      "In <Ifn=sPO00iV18_A8NZ@andrew.cmu.edu> jr4q+@andrew.cmu.edu (Jason M. Roth) writes:\n",
      "\n",
      ">>R&T had an article on cars of the SC1 ilk and they liked the Civic Ex,\n",
      ">>the Escort GT and the MX-3 best of all, and the SC1 was way down the\n",
      ">>list except for braking.\n",
      "\n",
      ">I just looked at that article; first of all, this summary is inaccurate;\n",
      ">of 10 cars, the SC1\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.2143\n",
      "From: bep1@cbnewsg.cb.att.com (bentz.e.puryear)\n",
      "Subject: Re: Sport Utility Vehical comparisons? Any Opinions?\n",
      "Organization: AT&T\n",
      "Lines: 51\n",
      "\n",
      "From article <1r1i7mINN4n4@cronkite.cisco.com>, by kmac@cisco.com (Karl Elvis MacRae):\n",
      "> \n",
      "> \n",
      "> \tI just read articals on this in Road and Track and Car and Driver\n",
      "> \t(Is that one mag or two? =B^), and I was wondering if people out\n",
      "> \tthere have any opinions that differed from what these mags have to\n",
      "> \tsay...\n",
      "> \n",
      "> \n",
      "> \tI'm looking at the following three SUV's;\n",
      "---\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "Similarity: 0.2057\n",
      "From: \"Arun G. Jayakumar\" <aj22+@andrew.cmu.edu>\n",
      "Subject: Re: Honda Mailing list?\n",
      "Organization: Freshman, Biology, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 6\n",
      "NNTP-Posting-Host: andrew.cmu.edu\n",
      "In-Reply-To: <94539@hydra.gatech.EDU>\n",
      "\n",
      "Excerpts from netnews.rec.autos: 24-Apr-93 Honda Mailing list? by James\n",
      "B. Atkins@prism.ga \n",
      ">         Is there a Honda mailing list, and if so how do I subscribe to it?\n",
      "\n",
      "If you look at their magazine ads, they may have a phone number to call\n",
      "and you can ask for a catalog\n",
      "---\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Przykladowe zapytanie :\n",
    "query = \"toyota and honda are the best cars\" \n",
    "top_documents = get_similar_docs_by_cosine(query, 5) \n",
    "# Wypisz wyniki \n",
    "for doc, score in top_documents: \n",
    "    print(f\"------------------------------\")\n",
    "    print(f\"Similarity: {score:.4f}\")\n",
    "    print(f\"{doc[:500]}\\n---\\n\")\n",
    "    print(f\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "82f0c63e-9f39-4017-9a6d-2428980eba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad zad2. a) Wnioski:\n",
    "# Dzieki funkcji get_similar_docs_by_cosine obliczylem miare podobienstw miedzy zapytaniem (query) oraz kazdym dokumentem w korpusie.\n",
    "# Wynioki zostaly posortowane od wartosci najwiekszej do najmniejszej po wartosci podobienstwa(similarity).\n",
    "# Wyswietlone wyniki powyzej pokazuja maile o najwiekszym podobienstwie do zadanego zapytania.\n",
    "# W przypadku zapytan \"reading Bible\" czy \"toyota and honda are the best cars\"  wskazane zostaly prawidlowo emaile dotyczace danego zagadnienia\n",
    "# Stopien podobienstwa wyswietlonych emaili 0.2 - 0.22 oraz 0.39 - 0.42. \n",
    "# Przy tym stopniu podobienstwa 0.39 - 0.42.  prawidlowo oceniam dobor emaili do zadanego zapytania (query) \n",
    "# Zauwazylem , ze przy stopniu podobienstwa 0.2 - 0.22 ten dobor maili tez oceniam jako prawidlowy i zgodny z tematem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb2b104a-d0a5-445d-aa6d-c9d958c38de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadanie 2.B  \n",
    "# Wypróbuj iloczyn skalarny zamiast podobieństwa kosinusowego, porównaj do wyników\n",
    "# z punktu a) i opisz w sprawozdaniu różnicę i jej przyczyny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32bc3672-6f69-4427-82b6-3d675c337a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_docs_by_scalar(query, vectorizer, tfidf_matrix, top_n): \n",
    "    # Konwersja zapytania do wektora TF-IDF \n",
    "    query_vector = vectorizer.transform([query]) \n",
    "    # Obliczenie iloczynu skalarnego między zapytaniem a wszystkimi dokumentami \n",
    "    scalar_products = np.dot(query_vector, tfidf_matrix.T).toarray().flatten() \n",
    "    # Znalezienie indeksów dokumentów o najwyższym iloczynie skalarnym \n",
    "    top_indices = scalar_products.argsort()[-top_n:][::-1] \n",
    "    return top_indices, scalar_products[top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "390fee1f-bebc-426f-8157-b1f93e634ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.3241\n",
      "From: carl_f_hoffman@cup.portal.com\n",
      "Subject: 1993 Infiniti G20\n",
      "Organization: The Portal System (TM)\n",
      "Lines: 26\n",
      "\n",
      "\n",
      "I am thinking about getting an Infiniti G20.\n",
      "In consumer reports it is ranked high in many\n",
      "catagories including highest in reliability index for compact cars.\n",
      "Mitsubushi Galant was second followed by Honda Accord).\n",
      "\n",
      "A couple of things though:\n",
      "1) In looking around I have yet to see anyone driving this\n",
      "   car. I see lots of Honda's and Toyota's.\n",
      "2) There is a special deal where I can get\n",
      "---\n",
      "\n",
      "Similarity: 0.2480\n",
      "From: gt4722a@prism.gatech.EDU (James B. Atkins)\n",
      "Subject: Honda Mailing list?\n",
      "Organization: Georgia Institute of Technology\n",
      "Lines: 2\n",
      "\n",
      "\n",
      "\tIs there a Honda mailing list, and if so how do I subscribe to it?\n",
      "\n",
      "---\n",
      "\n",
      "Similarity: 0.2246\n",
      "From: srihari@cirrus.com (Srihari Shoroff)\n",
      "Subject: Re: Instead of a Saturn SC2, What???\n",
      "Organization: Cirrus Logic Inc.\n",
      "Distribution: na\n",
      "Lines: 24\n",
      "\n",
      "In <Ifn=sPO00iV18_A8NZ@andrew.cmu.edu> jr4q+@andrew.cmu.edu (Jason M. Roth) writes:\n",
      "\n",
      ">>R&T had an article on cars of the SC1 ilk and they liked the Civic Ex,\n",
      ">>the Escort GT and the MX-3 best of all, and the SC1 was way down the\n",
      ">>list except for braking.\n",
      "\n",
      ">I just looked at that article; first of all, this summary is inaccurate;\n",
      ">of 10 cars, the SC1\n",
      "---\n",
      "\n",
      "Similarity: 0.2143\n",
      "From: bep1@cbnewsg.cb.att.com (bentz.e.puryear)\n",
      "Subject: Re: Sport Utility Vehical comparisons? Any Opinions?\n",
      "Organization: AT&T\n",
      "Lines: 51\n",
      "\n",
      "From article <1r1i7mINN4n4@cronkite.cisco.com>, by kmac@cisco.com (Karl Elvis MacRae):\n",
      "> \n",
      "> \n",
      "> \tI just read articals on this in Road and Track and Car and Driver\n",
      "> \t(Is that one mag or two? =B^), and I was wondering if people out\n",
      "> \tthere have any opinions that differed from what these mags have to\n",
      "> \tsay...\n",
      "> \n",
      "> \n",
      "> \tI'm looking at the following three SUV's;\n",
      "---\n",
      "\n",
      "Similarity: 0.2057\n",
      "From: \"Arun G. Jayakumar\" <aj22+@andrew.cmu.edu>\n",
      "Subject: Re: Honda Mailing list?\n",
      "Organization: Freshman, Biology, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 6\n",
      "NNTP-Posting-Host: andrew.cmu.edu\n",
      "In-Reply-To: <94539@hydra.gatech.EDU>\n",
      "\n",
      "Excerpts from netnews.rec.autos: 24-Apr-93 Honda Mailing list? by James\n",
      "B. Atkins@prism.ga \n",
      ">         Is there a Honda mailing list, and if so how do I subscribe to it?\n",
      "\n",
      "If you look at their magazine ads, they may have a phone number to call\n",
      "and you can ask for a catalog\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie danych 20newsgroups\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "documents = newsgroups.data\n",
    "\n",
    "# Stwórz wektor TF-IDF dla dokumentów\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Przykladowe zapytanie:\n",
    "query = \"toyota and honda are the best cars\"\n",
    "\n",
    "#Iloczyn skalarny podobienstw\n",
    "top_indices_skalar, top_scores_skalar = get_similar_docs_by_scalar(query, vectorizer, tfidf_matrix, 5)\n",
    "\n",
    "# Wyświetlenie wyników \n",
    "for doc_skalar, score_skalar in zip(top_indices_skalar, top_scores_skalar): \n",
    "    print(f\"Similarity: {score_skalar:.4f}\\n{documents[doc_skalar][:500]}\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53e77da5-4419-45ff-b9f6-b4d1a6c9faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad zad2. b) Wnioski:\n",
    "# TU OPISZ WNIOSKI Z PUNKTU B\n",
    "# W punkcie b zastosowalem iloczyn skalarny podobienstwa , wynik w porownaniu do podobiensta cosinusowego i dla tego samego\n",
    "# zapytania \"toyota and honda are the best cars\" jest identyczny. obliczony wskaznik podobienstwa tez jest na tym samym poziomie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9fb1d082-cefd-4f82-a2c0-53b996a67feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor each group in the 20newsgroups set, list the group that is most and least similar in meaning. \\nAs a measure of the similarity of two groups, use the average cosine similarity calculated for all pairs of documents from the compared groups.\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK 4\n",
    "'''\n",
    "For each group in the 20newsgroups set, list the group that is most and least similar in meaning. \n",
    "As a measure of the similarity of two groups, use the average cosine similarity calculated for all pairs of documents from the compared groups.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f2dee64-90c0-4f07-94e0-c0a753aadc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the average cosine similarity between two groups\n",
    "def get_average_cosine_similarity(group1_indices, group2_indices): \n",
    "    \"\"\"\n",
    "    Calculate the average cosine similarity between two groups of documents.\n",
    "\n",
    "    Parameters: \n",
    "        group1_indices : array-like Indices of the documents in the first group. \n",
    "        group2_indices : array-like Indices of the documents in the second group. \n",
    "        \n",
    "    Returns: \n",
    "        float: The average cosine similarity between the two groups of documents.   \n",
    "    \"\"\"\n",
    "    # Use cosine_similarity from sklearn\n",
    "    similarities = cosine_similarity(tfidf_matrix[group1_indices], tfidf_matrix[group2_indices]) \n",
    "    return np.mean(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ecb6a5a1-d19e-4474-b822-6eef6b66f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load needed libraries\n",
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ab03e41-e6aa-45bf-97ef-d67cb7ddc56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from 20newsgroups\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Divide documents between categories and labels\n",
    "documents = newsgroups.data\n",
    "categories = newsgroups.target_names \n",
    "labels = newsgroups.target\n",
    "\n",
    "# Transform text to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "#Print categories\n",
    "print(\"Categories:\") \n",
    "categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d92f4072-c87d-4c1c-bcc5-0d386cab4970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST similar groups:\n",
      "('soc.religion.christian', 'talk.religion.misc')\n",
      "similarity:\n",
      "0.02346466873647374\n",
      "\n",
      "LEAST similar groups:\n",
      "('comp.windows.x', 'rec.sport.hockey')\n",
      "similarity:\n",
      "0.0071516829474918995\n"
     ]
    }
   ],
   "source": [
    "# Calculating average cosine similarity for all pairs of groups\n",
    "group_similarities = {} \n",
    "for i in range(len(categories)): \n",
    "    for j in range(i+1, len(categories)): \n",
    "        group1_indices = np.where(labels == i)[0] \n",
    "        group2_indices = np.where(labels == j)[0] \n",
    "        similarity = get_average_cosine_similarity(group1_indices, group2_indices) \n",
    "        group_similarities[(categories[i], categories[j])] = similarity\n",
    "\n",
    "# Indicate most and least similar groups\n",
    "most_similar_groups = max(group_similarities, key=group_similarities.get) \n",
    "least_similar_groups = min(group_similarities, key=group_similarities.get)\n",
    "\n",
    "# Printing results\n",
    "print(\"MOST similar groups:\")\n",
    "print(f\"{most_similar_groups}\")\n",
    "print(f\"similarity:\") \n",
    "print(f\"{group_similarities[most_similar_groups]}\")\n",
    "print(\"\")\n",
    "print(\"LEAST similar groups:\")\n",
    "print(f\"{least_similar_groups}\")\n",
    "print(\"similarity:\")\n",
    "print(f\"{group_similarities[least_similar_groups]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e72861-9c05-4dc5-95ec-b53c2586838e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
